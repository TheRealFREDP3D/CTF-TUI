# .env - Environment variables for CTF Toolkit

# LiteLLM Model: Specify the LLM model to use.
# For Ollama models, use the format: ollama/model_name
# Example: LITELLM_MODEL="ollama/deepseek-r1:1.5b"
#LITELLM_MODEL="ollama/deepseek-r1:1.5b"
LITELLM_MODEL="gemini/gemini-2.0-flash"

# Ollama API Base URL: Specify the base URL for your Ollama instance.
# Default is usually http://localhost:11434
OLLAMA_API_BASE="http://localhost:11434"

# Add other environment variables here as needed
# For example, API keys for other providers:
# OPENAI_API_KEY="your_openai_key"
# ANTHROPIC_API_KEY="your_anthropic_key"
# GEMINI_API_KEY="your_gemini_key"  
